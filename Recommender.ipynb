{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ea5bbfd-e529-469e-ad53-78b1df7bcc21",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import joblib  # Used for saving and loading scikit-learn models\n",
    "import os\n",
    "\n",
    "# --- 1. Define File Names ---\n",
    "DATA_FILE = 'Cleaned_Indian_Food_Dataset.csv'\n",
    "VECTORIZER_FILE = 'tfidf_vectorizer.joblib'\n",
    "DATA_OUTPUT_FILE = 'processed_dishes.csv'\n",
    "\n",
    "def train_model():\n",
    "    \"\"\"\n",
    "    Loads the data, trains the TF-IDF vectorizer, and saves the\n",
    "    artifacts (vectorizer and processed data) to disk.\n",
    "    \"\"\"\n",
    "    \n",
    "    print(f\"--- Starting Model Training ---\")\n",
    "    \n",
    "    # --- 2. Load and Prepare Data ---\n",
    "    if not os.path.exists(DATA_FILE):\n",
    "        print(f\"Error: Data file not found at {DATA_FILE}\")\n",
    "        return\n",
    "\n",
    "    print(f\"Loading data from {DATA_FILE}...\")\n",
    "    df = pd.read_csv(DATA_FILE)\n",
    "    \n",
    "    # Select relevant columns and drop rows with no ingredients\n",
    "    # We keep URL and other info to show in the recommendation\n",
    "    df_processed = df[['TranslatedRecipeName', 'Cleaned-Ingredients', 'Cuisine', 'TotalTimeInMins', 'URL']].copy()\n",
    "    \n",
    "    # Critically, drop any rows where ingredients are missing\n",
    "    df_processed = df_processed.dropna(subset=['Cleaned-Ingredients'])\n",
    "    \n",
    "    # Reset index to ensure our .iloc[] matching works correctly\n",
    "    df_processed = df_processed.reset_index(drop=True)\n",
    "    \n",
    "    print(f\"Data loaded and processed. Total dishes: {len(df_processed)}\")\n",
    "\n",
    "    # --- 3. \"Train\" the TF-IDF Vectorizer ---\n",
    "    print(\"Training TF-IDF vectorizer...\")\n",
    "    \n",
    "    # Initialize the vectorizer. You could tune this, e.g.:\n",
    "    # max_features=5000 (to limit vocab size)\n",
    "    # min_df=2 (to ignore ingredients that appear in only 1 dish)\n",
    "    tfidf_vectorizer = TfidfVectorizer()\n",
    "\n",
    "    # Fit and transform the ingredients column.\n",
    "    # This step \"learns\" the vocabulary and IDF weights.\n",
    "    # The resulting tfidf_matrix is our numerical representation of all dishes.\n",
    "    tfidf_matrix = tfidf_vectorizer.fit_transform(df_processed['Cleaned-Ingredients'])\n",
    "    \n",
    "    print(f\"Vectorizer trained. TF-IDF matrix shape: {tfidf_matrix.shape}\")\n",
    "\n",
    "    # --- 4. Save the \"Model\" Artifacts ---\n",
    "    # We save the vectorizer so we can use the *exact same* vocabulary\n",
    "    # and weights to transform user input later.\n",
    "    print(f\"Saving vectorizer to {VECTORIZER_FILE}...\")\n",
    "    joblib.dump(tfidf_vectorizer, VECTORIZER_FILE)\n",
    "    \n",
    "    # We save the processed data to match matrix indices to dish names\n",
    "    print(f\"Saving processed data to {DATA_OUTPUT_FILE}...\")\n",
    "    df_processed.to_csv(DATA_OUTPUT_FILE, index=False)\n",
    "    \n",
    "    print(\"--- Model training finished. Artifacts saved. ---\")\n",
    "\n",
    "\n",
    "# --- 5. Define the Recommendation Function ---\n",
    "# This function would typically be in your main application (e.g., Flask app),\n",
    "# not in the training script. We include it here for a complete example.\n",
    "# It shows how to LOAD the artifacts you just saved.\n",
    "\n",
    "def get_recommendations(user_ingredients, top_n=5):\n",
    "    \"\"\"\n",
    "    Loads the trained model artifacts and returns dish recommendations.\n",
    "    \n",
    "    Args:\n",
    "        user_ingredients (list): A list of ingredient strings.\n",
    "        top_n (int): Number of recommendations to return.\n",
    "        \n",
    "    Returns:\n",
    "        pandas.DataFrame: Top N recommended dishes.\n",
    "    \"\"\"\n",
    "    \n",
    "    print(f\"\\n--- Getting Recommendations for: {user_ingredients} ---\")\n",
    "    \n",
    "    # --- 1. Load Model Artifacts ---\n",
    "    # In a real app, you'd load these once when the app starts.\n",
    "    try:\n",
    "        vectorizer = joblib.load(VECTORIZER_FILE)\n",
    "        data = pd.read_csv(DATA_OUTPUT_FILE)\n",
    "    except FileNotFoundError:\n",
    "        print(\"Error: Model files not found. Please run the train_model() function first.\")\n",
    "        return pd.DataFrame()\n",
    "\n",
    "    # --- 2. Re-create the TF-IDF Matrix ---\n",
    "    # We don't need to save the giant matrix. We can recreate it \n",
    "    # on the fly using the saved vectorizer and data.\n",
    "    # Use .transform() as the vectorizer is already fitted.\n",
    "    tfidf_matrix = vectorizer.transform(data['Cleaned-Ingredients'])\n",
    "\n",
    "    # --- 3. Process User Input ---\n",
    "    # Join the list into a single string\n",
    "    input_string = \" \".join(user_ingredients)\n",
    "    \n",
    "    # Transform the user's input using the FITTED vectorizer\n",
    "    input_vector = vectorizer.transform([input_string])\n",
    "    \n",
    "    # --- 4. Compute Cosine Similarity ---\n",
    "    # Calculate the similarity between the user's input and all dishes\n",
    "    cosine_scores = cosine_similarity(input_vector, tfidf_matrix)\n",
    "    \n",
    "    # Flatten the 2D array to a 1D array of scores\n",
    "    scores = cosine_scores.flatten()\n",
    "    \n",
    "    # --- 5. Get Top N Matches ---\n",
    "    # Get the indices of the highest-scoring dishes\n",
    "    top_indices = scores.argsort()[::-1][:top_n]\n",
    "    \n",
    "    # --- 6. Format and Return Results ---\n",
    "    recommendations = data.iloc[top_indices].copy()\n",
    "    recommendations['similarity_score'] = scores[top_indices]\n",
    "    \n",
    "    # Filter out results with 0 similarity\n",
    "    recommendations = recommendations[recommendations['similarity_score'] > 0]\n",
    "    \n",
    "    return recommendations[['TranslatedRecipeName', 'Cuisine', 'TotalTimeInMins', 'similarity_score', 'URL']]\n",
    "\n",
    "# --- Main execution block ---\n",
    "if __name__ == \"__main__\":\n",
    "    \n",
    "    # Step 1: Run the training\n",
    "    # You only need to do this ONCE (or when your data changes)\n",
    "    train_model()\n",
    "    \n",
    "    # Step 2: Test the recommendation function\n",
    "    # This is what your application will do\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*50)\n",
    "    print(\"Example 1: 'Rice', 'Milk', 'Sugar'\")\n",
    "    test_ingredients_1 = ['rice', 'milk', 'sugar', 'cardamom']\n",
    "    recs1 = get_recommendations(test_ingredients_1)\n",
    "    print(recs1)\n",
    "    print(\"=\"*50)\n",
    "\n",
    "    print(\"\\n\" + \"=\"*50)\n",
    "    print(\"Example 2: 'Chicken', 'Onion', 'Tomato'\")\n",
    "    test_ingredients_2 = ['chicken', 'onion', 'tomato', 'ginger', 'garlic']\n",
    "    recs2 = get_recommendations(test_ingredients_2, top_n=3)\n",
    "    print(recs2)\n",
    "    print(\"=\"*50)\n",
    "\n",
    "    print(\"\\n\" + \"=\"*50)\n",
    "    print(\"Example 3: 'Spinach', 'Paneer', 'Cream'\")\n",
    "    test_ingredients_3 = ['spinach', 'paneer', 'cream', 'ghee']\n",
    "    recs3 = get_recommendations(test_ingredients_3)\n",
    "    print(recs3)\n",
    "    print(\"=\"*50)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
